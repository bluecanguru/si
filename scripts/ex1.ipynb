{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4915c8df",
   "metadata": {},
   "source": [
    "Exercise 1 - NumPy array Indexing/Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d7ee84",
   "metadata": {},
   "source": [
    "1.1) In this exercise, we will use the iris dataset. Load the \"iris.csv\" using the appropriate method for this file type (use the new functions from the package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035d9e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from si.io.csv_file import read_csv\n",
    "\n",
    "data = read_csv('../datasets/iris/iris.csv', sep=',', features=True, label=True)\n",
    "data.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dca7a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01fb691",
   "metadata": {},
   "source": [
    "1.2) Select the penultimate independent variable.\n",
    "What is the dimension of the resulting array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61755a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,) [1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4\n",
      " 1.7 1.5 1.7 1.5 1.  1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2\n",
      " 1.3 1.5 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.\n",
      " 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.  4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.\n",
      " 4.9 4.7 4.3 4.4 4.8 5.  4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.\n",
      " 4.4 4.6 4.  3.3 4.2 4.2 4.2 4.3 3.  4.1 6.  5.1 5.9 5.6 5.8 6.6 4.5 6.3\n",
      " 5.8 6.1 5.1 5.3 5.5 5.  5.1 5.3 5.5 6.7 6.9 5.  5.7 4.9 6.7 4.9 5.7 6.\n",
      " 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9\n",
      " 5.7 5.2 5.  5.2 5.4 5.1]\n"
     ]
    }
   ],
   "source": [
    "# select the penultimate row\n",
    "p_var = data.X[:,-2]\n",
    "# uses shape to get the dimensions of the array\n",
    "dim = p_var.shape\n",
    "print(dim, p_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa21f2",
   "metadata": {},
   "source": [
    "1.3) Select the last 10 samples from the iris dataset.\n",
    "What is the mean of the last 10 samples for each independent variable/feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e2751d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.45 3.03 5.33 2.17]\n"
     ]
    }
   ],
   "source": [
    "last_10 = data.X[-10:]\n",
    "mean_10 = last_10.mean(axis=0)\n",
    "print(mean_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6facb98d",
   "metadata": {},
   "source": [
    "1.4) Select all samples from the dataset with values less than or equal to 6 for all independent variables/features.\n",
    "How many samples do you obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1874ea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 4)\n"
     ]
    }
   ],
   "source": [
    "# mask for values less than or equal to 6\n",
    "mask = (data.X <= 6).all(axis=1)\n",
    "filtered = data.X[mask]\n",
    "print(filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fbf991",
   "metadata": {},
   "source": [
    "1.5) Select all samples with a class/label different from 'Iris-setosa'. \n",
    "How many samples do you obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c0915b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n"
     ]
    }
   ],
   "source": [
    "mask = data.y != 'Iris-setosa'\n",
    "filtered_data = data.X[mask]\n",
    "print(filtered_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4ca8f8",
   "metadata": {},
   "source": [
    "Examples of how to use these methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871c23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8b60c3b",
   "metadata": {},
   "source": [
    "3.3) Test the SelectPercentile class in a Jupyter notebook using the \"iris.csv\" dataset(classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0650134a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed dataset shape: (150, 2)\n",
      "Selected features: ['petal_length', 'petal_width']\n"
     ]
    }
   ],
   "source": [
    "from si.io.csv_file import read_csv\n",
    "from si.data.dataset import Dataset\n",
    "# Ensure this line reloads the new code\n",
    "from si.feature_selection.select_percentile import SelectPercentile \n",
    "\n",
    "# Load the iris dataset\n",
    "data = read_csv('../datasets/iris/iris.csv', sep=',', features=True, label=True)\n",
    "dataset = Dataset(data.X, data.y, features=data.features, label=data.label)\n",
    "\n",
    "# Initialize SelectPercentile with a percentile of 50%\n",
    "# The default score_func (f_classification) is used here.\n",
    "selector = SelectPercentile(percentile=0.5)\n",
    "\n",
    "# Fit and transform the dataset\n",
    "transformed_dataset = selector.fit_transform(dataset) # This should now work\n",
    "\n",
    "# Print the transformed dataset shape and selected features\n",
    "print(\"Transformed dataset shape:\", transformed_dataset.X.shape)\n",
    "print(\"Selected features:\", transformed_dataset.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a8bbc8",
   "metadata": {},
   "source": [
    "4.1) Test tanimoto similarity in a jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "224732f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25 0.25 0.25]\n"
     ]
    }
   ],
   "source": [
    "from si.statistics.tanimoto_similarity import tanimoto_similarity\n",
    "\n",
    "x = [True, False, True, True]\n",
    "y = [\n",
    "    [True, True, False, False],\n",
    "    [False, False, True, True],\n",
    "    [True, False, True, False]\n",
    "]\n",
    "\n",
    "similarities = tanimoto_similarity(x, y)\n",
    "print(similarities)  # Output: [0.25, 0.6, 0.666...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabcb260",
   "metadata": {},
   "source": [
    "5.2) Test the PCA class in a jupyter notebook using the iris.csv dataset (classificação)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "915a2a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance: [0.92461621 0.05301557]\n",
      "[[-2.68420713 -0.32660731]\n",
      " [-2.71539062  0.16955685]\n",
      " [-2.88981954  0.13734561]\n",
      " [-2.7464372   0.31112432]\n",
      " [-2.72859298 -0.33392456]\n",
      " [-2.27989736 -0.74778271]\n",
      " [-2.82089068  0.08210451]\n",
      " [-2.62648199 -0.17040535]\n",
      " [-2.88795857  0.57079803]\n",
      " [-2.67384469  0.1066917 ]\n",
      " [-2.50652679 -0.65193501]\n",
      " [-2.61314272 -0.02152063]\n",
      " [-2.78743398  0.22774019]\n",
      " [-3.22520045  0.50327991]\n",
      " [-2.64354322 -1.1861949 ]\n",
      " [-2.38386932 -1.34475434]\n",
      " [-2.6225262  -0.81808967]\n",
      " [-2.64832273 -0.31913667]\n",
      " [-2.19907796 -0.87924409]\n",
      " [-2.58734619 -0.52047364]\n",
      " [-2.3105317  -0.39786782]\n",
      " [-2.54323491 -0.44003175]\n",
      " [-3.21585769 -0.14161557]\n",
      " [-2.30312854 -0.10552268]\n",
      " [-2.35617109  0.03120959]\n",
      " [-2.50791723  0.13905634]\n",
      " [-2.469056   -0.13788731]\n",
      " [-2.56239095 -0.37468456]\n",
      " [-2.63982127 -0.31929007]\n",
      " [-2.63284791  0.19007583]\n",
      " [-2.58846205  0.19739308]\n",
      " [-2.41007734 -0.41808001]\n",
      " [-2.64763667 -0.81998263]\n",
      " [-2.59715948 -1.10002193]\n",
      " [-2.67384469  0.1066917 ]\n",
      " [-2.86699985 -0.0771931 ]\n",
      " [-2.62522846 -0.60680001]\n",
      " [-2.67384469  0.1066917 ]\n",
      " [-2.98184266  0.48025005]\n",
      " [-2.59032303 -0.23605934]\n",
      " [-2.77013891 -0.27105942]\n",
      " [-2.85221108  0.93286537]\n",
      " [-2.99829644  0.33430757]\n",
      " [-2.4055141  -0.19591726]\n",
      " [-2.20883295 -0.44269603]\n",
      " [-2.71566519  0.24268148]\n",
      " [-2.53757337 -0.51036755]\n",
      " [-2.8403213   0.22057634]\n",
      " [-2.54268576 -0.58628103]\n",
      " [-2.70391231 -0.11501085]\n",
      " [ 1.28479459 -0.68543919]\n",
      " [ 0.93241075 -0.31919809]\n",
      " [ 1.46406132 -0.50418983]\n",
      " [ 0.18096721  0.82560394]\n",
      " [ 1.08713449 -0.07539039]\n",
      " [ 0.64043675  0.41732348]\n",
      " [ 1.09522371 -0.28389121]\n",
      " [-0.75146714  1.00110751]\n",
      " [ 1.04329778 -0.22895691]\n",
      " [-0.01019007  0.72057487]\n",
      " [-0.5110862   1.26249195]\n",
      " [ 0.51109806  0.10228411]\n",
      " [ 0.26233576  0.5478933 ]\n",
      " [ 0.98404455  0.12436042]\n",
      " [-0.174864    0.25181557]\n",
      " [ 0.92757294 -0.46823621]\n",
      " [ 0.65959279  0.35197629]\n",
      " [ 0.23454059  0.33192183]\n",
      " [ 0.94236171  0.54182226]\n",
      " [ 0.0432464   0.58148945]\n",
      " [ 1.11624072  0.08421401]\n",
      " [ 0.35678657  0.06682383]\n",
      " [ 1.29646885  0.32756152]\n",
      " [ 0.92050265  0.18239036]\n",
      " [ 0.71400821 -0.15037915]\n",
      " [ 0.89964086 -0.32961098]\n",
      " [ 1.33104142 -0.24466952]\n",
      " [ 1.55739627 -0.26739258]\n",
      " [ 0.81245555  0.16233157]\n",
      " [-0.30733476  0.36508661]\n",
      " [-0.07034289  0.70253793]\n",
      " [-0.19188449  0.67749054]\n",
      " [ 0.13499495  0.31170964]\n",
      " [ 1.37873698  0.42120514]\n",
      " [ 0.58727485  0.48328427]\n",
      " [ 0.8072055  -0.19505396]\n",
      " [ 1.22042897 -0.40803534]\n",
      " [ 0.81286779  0.370679  ]\n",
      " [ 0.24519516  0.26672804]\n",
      " [ 0.16451343  0.67966147]\n",
      " [ 0.46303099  0.66952655]\n",
      " [ 0.89016045  0.03381244]\n",
      " [ 0.22887905  0.40225762]\n",
      " [-0.70708128  1.00842476]\n",
      " [ 0.35553304  0.50321849]\n",
      " [ 0.33112695  0.21118014]\n",
      " [ 0.37523823  0.29162202]\n",
      " [ 0.64169028 -0.01907118]\n",
      " [-0.90846333  0.75156873]\n",
      " [ 0.29780791  0.34701652]\n",
      " [ 2.53172698  0.01184224]\n",
      " [ 1.41407223  0.57492506]\n",
      " [ 2.61648461 -0.34193529]\n",
      " [ 1.97081495  0.18112569]\n",
      " [ 2.34975798  0.04188255]\n",
      " [ 3.39687992 -0.54716805]\n",
      " [ 0.51938325  1.19135169]\n",
      " [ 2.9320051  -0.35237701]\n",
      " [ 2.31967279  0.24554817]\n",
      " [ 2.91813423 -0.78038063]\n",
      " [ 1.66193495 -0.2420384 ]\n",
      " [ 1.80234045  0.21615461]\n",
      " [ 2.16537886 -0.21528028]\n",
      " [ 1.34459422  0.77641543]\n",
      " [ 1.5852673   0.53930705]\n",
      " [ 1.90474358 -0.11881899]\n",
      " [ 1.94924878 -0.04073026]\n",
      " [ 3.48876538 -1.17154454]\n",
      " [ 3.79468686 -0.25326557]\n",
      " [ 1.29832982  0.76101394]\n",
      " [ 2.42816726 -0.37678197]\n",
      " [ 1.19809737  0.60557896]\n",
      " [ 3.49926548 -0.45677347]\n",
      " [ 1.38766825  0.20403099]\n",
      " [ 2.27585365 -0.33338653]\n",
      " [ 2.61419383 -0.55836695]\n",
      " [ 1.25762518  0.179137  ]\n",
      " [ 1.29066965  0.11642525]\n",
      " [ 2.12285398  0.21085488]\n",
      " [ 2.3875644  -0.46251925]\n",
      " [ 2.84096093 -0.37274259]\n",
      " [ 3.2323429  -1.37052404]\n",
      " [ 2.15873837  0.21832553]\n",
      " [ 1.4431026   0.14380129]\n",
      " [ 1.77964011  0.50146479]\n",
      " [ 3.07652162 -0.68576444]\n",
      " [ 2.14498686 -0.13890661]\n",
      " [ 1.90486293 -0.04804751]\n",
      " [ 1.16885347  0.1645025 ]\n",
      " [ 2.10765373 -0.37148225]\n",
      " [ 2.31430339 -0.18260885]\n",
      " [ 1.92245088 -0.40927118]\n",
      " [ 1.41407223  0.57492506]\n",
      " [ 2.56332271 -0.2759745 ]\n",
      " [ 2.41939122 -0.30350394]\n",
      " [ 1.94401705 -0.18741522]\n",
      " [ 1.52566363  0.37502085]\n",
      " [ 1.76404594 -0.07851919]\n",
      " [ 1.90162908 -0.11587675]\n",
      " [ 1.38966613  0.28288671]]\n"
     ]
    }
   ],
   "source": [
    "from si.io.csv_file import read_csv\n",
    "from si.data.dataset import Dataset\n",
    "from si.decomposition.pca import PCA\n",
    "\n",
    "# Load the iris dataset\n",
    "data = read_csv('../datasets/iris/iris.csv', sep=',', features=True, label=True)\n",
    "dataset = Dataset(data.X, data.y, features=data.features, label=data.label)\n",
    "\n",
    "# Fit and transform using PCA\n",
    "pca = PCA(n_components=2)\n",
    "transformed_dataset = pca.fit_transform(dataset)\n",
    "\n",
    "# Print the explained variance\n",
    "print(\"Explained variance:\", pca.explained_variance)\n",
    "\n",
    "# Print the transformed data\n",
    "print(transformed_dataset.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff887c",
   "metadata": {},
   "source": [
    "6.2) Test the \"stratified_train_test_split\" function with the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54bd6bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution: (array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object), array([40, 40, 40]))\n",
      "Test class distribution: (array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object), array([10, 10, 10]))\n"
     ]
    }
   ],
   "source": [
    "from si.io.csv_file import read_csv\n",
    "from si.data.dataset import Dataset\n",
    "from si.model_selection.split import stratified_train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load the iris dataset\n",
    "data = read_csv('../datasets/iris/iris.csv', sep=',', features=True, label=True)\n",
    "dataset = Dataset(data.X, data.y, features=data.features, label=data.label)\n",
    "\n",
    "# Perform stratified train-test split\n",
    "train_data, test_data = stratified_train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the class distribution in train and test sets\n",
    "print(\"Train class distribution:\", np.unique(train_data.y, return_counts=True))\n",
    "print(\"Test class distribution:\", np.unique(test_data.y, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4173d5c3",
   "metadata": {},
   "source": [
    "7.3) Test the \"KNNRegressor\" class using the \"cpu.csv\" dataset (regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d873cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 105.0\n"
     ]
    }
   ],
   "source": [
    "from si.io.csv_file import read_csv\n",
    "from si.data.dataset import Dataset\n",
    "from si.models.knn_regressor import KNNRegressor\n",
    "from si.metrics.rmse import rmse\n",
    "from si.model_selection.split import train_test_split\n",
    "\n",
    "# Load the CPU dataset\n",
    "data = read_csv('../datasets/cpu/cpu.csv', sep=',', features=True, label=True)\n",
    "dataset = Dataset(data.X, data.y, features=data.features, label=data.label)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the KNNRegressor\n",
    "knn = KNNRegressor(k=5)\n",
    "knn.fit(train_data)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = knn.predict(test_data.X)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_score = rmse(test_data.y, y_pred)\n",
    "print(f\"RMSE: {rmse_score:.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6499393",
   "metadata": {},
   "source": [
    "8.1) Test the \"RidgeRegressionLeastSquares\" class using the \"cpu.csv\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0ab5cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 5806.1\n"
     ]
    }
   ],
   "source": [
    "from si.io.csv_file import read_csv\n",
    "from si.data.dataset import Dataset\n",
    "from si.models.ridge_regression_least_squares import RidgeRegressionLeastSquares\n",
    "from si.model_selection.split import train_test_split\n",
    "\n",
    "# Load your dataset\n",
    "data = read_csv('../datasets/cpu/cpu.csv', sep=',', features=True, label=True)\n",
    "dataset = Dataset(data.X, data.y, features=data.features, label=data.label)\n",
    "\n",
    "# Split the dataset\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the model\n",
    "ridge = RidgeRegressionLeastSquares(l2_penalty=1.0, scale=True)\n",
    "ridge.fit(train_data)\n",
    "\n",
    "# Predict and score\n",
    "y_pred = ridge.predict(test_data.X)\n",
    "mse_score = ridge.score(test_data)\n",
    "print(f\"MSE: {mse_score:.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10140b2e",
   "metadata": {},
   "source": [
    "9.2) Test the random forest class using the following protocol:\n",
    "1.Use the iris.csv dataset\n",
    "2.Split the data into train and test sets\n",
    "3.Create the RandomForestClassifier model\n",
    "4.Train the model. What is the score of the model on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca8bbe0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Initialize and fit the RandomForestClassifier\u001b[39;00m\n\u001b[32m     14\u001b[39m rf = RandomForestClassifier(n_estimators=\u001b[32m100\u001b[39m, max_features=\u001b[38;5;28;01mNone\u001b[39;00m, min_sample_split=\u001b[32m2\u001b[39m, max_depth=\u001b[38;5;28;01mNone\u001b[39;00m, mode=\u001b[33m'\u001b[39m\u001b[33mgini\u001b[39m\u001b[33m'\u001b[39m, seed=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mrf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Score the model on the test set\u001b[39;00m\n\u001b[32m     18\u001b[39m score = rf.score(test_data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/catia/si/src/si/base/estimator.py:32\u001b[39m, in \u001b[36mEstimator.fit\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: Dataset) -> \u001b[33m'\u001b[39m\u001b[33mEstimator\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     19\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03m    Fit the estimator to the data.\u001b[39;00m\n\u001b[32m     21\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[33;03m        The fitted estimator.\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mself\u001b[39m._is_fitted = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/catia/si/src/si/models/random_forest_classifier.py:83\u001b[39m, in \u001b[36mRandomForestClassifier._fit\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Create and train a decision tree\u001b[39;00m\n\u001b[32m     78\u001b[39m tree = DecisionTreeClassifier(\n\u001b[32m     79\u001b[39m     min_sample_split=\u001b[38;5;28mself\u001b[39m.min_sample_split,\n\u001b[32m     80\u001b[39m     max_depth=\u001b[38;5;28mself\u001b[39m.max_depth,\n\u001b[32m     81\u001b[39m     mode=\u001b[38;5;28mself\u001b[39m.mode\n\u001b[32m     82\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_bootstrap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_bootstrap\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Append the features and tree to the list\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.trees.append((feature_indices, tree))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/catia/si/src/si/base/estimator.py:32\u001b[39m, in \u001b[36mEstimator.fit\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: Dataset) -> \u001b[33m'\u001b[39m\u001b[33mEstimator\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     19\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03m    Fit the estimator to the data.\u001b[39;00m\n\u001b[32m     21\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[33;03m        The fitted estimator.\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mself\u001b[39m._is_fitted = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/catia/si/src/si/models/decision_tree_classifier.py:232\u001b[39m, in \u001b[36mDecisionTreeClassifier._fit\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    219\u001b[39m \u001b[33;03mFits the decision tree classifier to a dataset.\u001b[39;00m\n\u001b[32m    220\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m \u001b[33;03m    The fitted model.\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[38;5;28mself\u001b[39m.dataset = dataset\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m \u001b[38;5;28mself\u001b[39m.tree = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/catia/si/src/si/models/decision_tree_classifier.py:92\u001b[39m, in \u001b[36mDecisionTreeClassifier._build_tree\u001b[39m\u001b[34m(self, dataset, current_depth)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[33;03mBuilds a decision tree recursively.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m \u001b[33;03m    The root node of the tree.\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     91\u001b[39m n_samples = dataset.shape()[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_samples >= \u001b[38;5;28mself\u001b[39m.min_sample_split \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mcurrent_depth\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_depth\u001b[49m:\n\u001b[32m     93\u001b[39m     best_split = \u001b[38;5;28mself\u001b[39m._get_best_split(dataset)\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m best_split[\u001b[33m'\u001b[39m\u001b[33minfo_gain\u001b[39m\u001b[33m'\u001b[39m] > \u001b[32m0\u001b[39m:\n",
      "\u001b[31mTypeError\u001b[39m: '<=' not supported between instances of 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "from si.io.csv_file import read_csv\n",
    "from si.data.dataset import Dataset\n",
    "from si.models.random_forest_classifier import RandomForestClassifier\n",
    "from si.model_selection.split import train_test_split\n",
    "\n",
    "# Load the iris dataset\n",
    "data = read_csv('../datasets/iris/iris.csv', sep=',', features=True, label=True)\n",
    "dataset = Dataset(data.X, data.y, features=data.features, label=data.label)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, max_features=None, min_sample_split=2, max_depth=None, mode='gini', seed=42)\n",
    "rf.fit(train_data)\n",
    "\n",
    "# Score the model on the test set\n",
    "score = rf.score(test_data)\n",
    "print(f\"Test set accuracy: {score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
